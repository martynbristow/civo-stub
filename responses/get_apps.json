[{"name":"argo","title":"Argo CI/CD","version":"(default)","default":null,"dependencies":null,"maintainer":"The Argo Project","description":"Declarative continuous deployment for Kubernetes","post_install":"## Argo CI/CD\n\n### Usage instruction\n\nSee the [documentations](https://argoproj.github.io/argo-cd/)","url":"https://github.com/argoproj/argo-cd/","category":"ci_cd","image_url":"https://api.civo.com/k3s-marketplace/argo.png","plans":null},{"name":"Bitwardenrs","title":null,"version":"1.17.0","default":null,"dependencies":["longhorn","cert-manager"],"maintainer":"keith@hubner.co.uk","description":"Open Source Password Manager (Bitwarden server API implementation written in Rust)","post_install":"## Bitwarden RS\n\n### This project is not associated with the Bitwarden project nor 8bit Solutions LLC.\n\nThis is a Bitwarden server API implementation written in Rust compatible with upstream Bitwarden clients*, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.\n\n### HTTPS\n\nAn ingress is automatically created during the application install. A certificate using cert manager and lets-encrypt is also applied automatically and registered against your Civo email address and the generated domain name.\n\n### Post installation\n\nOnce you have installed this app you will be able to connect to the web interface via https://rs.YOUR_CLUSTER_ID.k8s.civo.com\n\n\n\n","url":"https://github.com/dani-garcia/bitwarden_rs","category":"management","image_url":"https://api.civo.com/k3s-marketplace/bitwardenrs.png","plans":[{"label":"1GB","configuration":{"VOLUME_SIZE":{"value":"1Gi"}}},{"label":"2GB","configuration":{"VOLUME_SIZE":{"value":"2Gi"}}},{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}}]},{"name":"cert-manager","title":"Cert Manager","version":"v1.0.2","default":null,"dependencies":["Helm"],"maintainer":"alex@openfaas.com","description":"cert-manager is a native Kubernetes certificate management controller","post_install":"## cert-manager - a native Kubernetes certificate management controller\n\n### Get started\n\n[cert-manager docs](https://cert-manager.io/docs/)\n\n* Issue a [Certificate using HTTP Validation](https://cert-manager.io/docs/tutorials/acme/http-validation/)\n","url":"https://cert-manager.io/docs/release-notes/release-notes-1.0/","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/cert-manager.png","plans":null},{"name":"chaos-mesh","title":"Chaos Mesh","version":"(default)","default":null,"dependencies":["Helm"],"maintainer":"cwen@pingcap.com","description":"A Chaos Engineering Platform for Kubernetes","post_install":"## Chaos Mesh -  A Chaos Engineering Platform for Kubernetes\n\n### Usage instruction\n\nSee the [documentations](https://chaos-mesh.org/docs)\n\n### Log in Chaos Dashboard\n\nChaos Dashboard supports a security mode, which requires users to login with a token generated by Kubernetes. Each token is linked to a `service account`. You can only perform operations within the scope as allowed by the role that is associated with the service account. By default, the security mode is enabled when using helm to install Chaos Mesh. You can refer this [documentation](https://chaos-mesh.org/docs/user_guides/dashboard#log-in) to create the account and the token. \n\nIf you want to create the account later and start using Chaos Dashboard quickly, you can use the token of Chaos Mesh. Get the token by executing the command: \n\n```shell\nkubectl -n chaos-testing describe secret $(kubectl -n chaos-testing get secret | grep chaos-controller-manager | awk '{print $1}')\n```\n","url":"https://github.com/chaos-mesh/chaos-mesh","category":"ci_cd","image_url":"https://api.civo.com/k3s-marketplace/chaos-mesh.png","plans":null},{"name":"docker-registry","title":"Docker Registry","version":"ALPHA","default":null,"dependencies":["Helm","cert-manager","Traefik"],"maintainer":"alejandro@civo.com","description":"A registry is a storage and content delivery system, holding named Docker images, available in different tagged versions.","post_install":"## Docker Registry - Default ingress controller\n\n### Creation of the certificate\n\nThis will help you to create a valid certificate for your registry, you need apply this YAML file,\nyou only need replace only `registry.example.com` by your valid domain\n```yaml\napiVersion: cert-manager.io/v1alpha2\nkind: Certificate\nmetadata:\n  name: letsencrypt-prod\nspec:\n  secretName: registry.example.com-cert\n  dnsNames:\n  - registry.example.com\n  acme:\n    config:\n    - http01:\n        ingressClass: traefik\n      domains:\n      - registry.example.com\n  issuerRef:\n    name: letsencrypt-prod\n    kind: ClusterIssuer\n```\n\n### External access to your services\n\nTraefik is installed in K3s as the default ingress controller. To use it for your applications all you have to do is apply a YAML file like the one below to handle ingress:\n\n```yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: registry\n  namespace: default\n  annotations:\n    certmanager.k8s.io/cluster-issuer: letsencrypt-prod\n    kubernetes.io/ingress.class: \"traefik\"\n    nginx.ingress.kubernetes.io/proxy-body-size: 50m\n    ingress.kubernetes.io/ssl-redirect: \"true\"\n    ingress.kubernetes.io/auth-type: basic\n    ingress.kubernetes.io/auth-secret: auth-ingress\n  labels:\n    app: docker-registry\nspec:\n  tls:\n  - hosts:\n    - registry.example.com\n    secretName: registry.example.com-cert\n  rules:\n  - host: registry.example.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: private-registry-docker-registry\n          servicePort: 5000\n```\nYou only need replace only `registry.example.com` by your valid domain.\nThis will open up http://registry.example.com (assuming you pointed that non-real domain record to your cluster's IPs) to the whole world.","url":null,"category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/docker-registry.png","plans":null},{"name":"dynamic-pv-scaler","title":"Dynamic PV Scaler","version":"0.1.0","default":null,"dependencies":["prometheus-operator"],"maintainer":"@iamabhishek-dubey","description":"Dynamic PV Scaler is a golang based Kubernetes application which has been created to overcome the scaling issue of PV in Kubernetes.","post_install":"","url":"https://opstree.github.io/","category":"storage","image_url":"https://api.civo.com/k3s-marketplace/dynamic-pv-scaler.png","plans":null},{"name":"falco-security","title":"Falco Security","version":"0.27","default":null,"dependencies":null,"maintainer":"amit2cha@gmail.com, Falco Maintainers","description":"Falco is a Cloud Native Runtime Security tool designed to detect anomalous activity in your applications.","post_install":"## Falco is a Cloud Native Runtime Security tool designed to detect anomalous activity in your applications\n\n### Falco community on Slack can help with the chart if there are any questions, but Civo are responsible for the install.sh and manifest.yaml\n\n### Get started\n\n[Falco Security docs](https://falco.org/docs/)\n\n\n[Add your Rules](https://falco.org/docs/rules/)\n\nFalco does not Expose to Web out of the box. You can use Following command \n``` kubectl port-forward service/falco-falcosidekick-ui 2802:2802 -n falco ```, But it's already noticed that it can trigger events because of kubectl port-forward triggers a Falco rule.\n\nYou can use following link to get more resources [At this Blog](https://blog.webdev-jogeleit.de/blog/falco-security-and-monitoring-on-rke-bare-metal-cluster-with-rancher/)\n\nFor advanced configurations like ingress visit (Values.yaml)[https://github.com/falcosecurity/charts/blob/427bf5c8eb1a80b93e142376eb338bde4efa899a/falcosidekick/values.yaml#L211]\n","url":"https://falco.org/","category":"security","image_url":"https://api.civo.com/k3s-marketplace/falco.png","plans":null},{"name":"Ghost","title":null,"version":"3.35.5","default":null,"dependencies":["longhorn"],"maintainer":"saka@lnxid.com","description":"Ghost is a free and open source blogging platform designed to simplify the process of online publishing for individual bloggers as well as online publications.","post_install":"# Ghost\n\nThis ghost blog using sqlite as the database backend.\n\n## External Access\n\nAn Ingress is created during the installation process. To access your ghost use `http://ghost.YOUR_CLUSTER_ID.k8s.civo.com`\n\n## Create Admin User\n\nBy default Ghost does not create Admin user during the installation process. In order to access your Ghost Dashboard you will need to create your Ghost Admin user first. This can be done right after your installation process via your browser.\n\nTo access your Ghost registration page simply access your Ghost installation via your browser using the following URL: `http://ghost.YOUR_CLUSTER_ID.k8s.civo.com`, after that follow step below :\n\n* Click `Create your account` button.  \n* Input your site title, username, email address and desired password ( at least 10 characters ).  \n* Invite your friend to Collaborate on your blog. This is optional, If you don't want to invite others just click text `I'll do this later, take me to my site!`.\n\n## Delete default user created by ghost\n\nBy default ghost create user name `Ghost` and create example post in your blog. You can follow this step to delete it.\n\n* Login to your ghost admin url `http://ghost.YOUR_CLUSTER_ID.k8s.civo.com/ghost`.  \n* Click the `Staff` menu in the left column.  \n* In the right column, click the user name `Ghost`.  \n* Click the option button in the upper right ( in the left of save button ).  \n* Chose `Delete button`\n\n## How to create your first blog post\n\nFollow this step to create your first blog post :\n\n* To begin your first blog post login to ghost admin url `http://ghost.YOUR_CLUSTER_ID.k8s.civo.com/ghost`.  \n* Inside the ghost admin menu, click `Posts` menu at the left column. Click `New post` button in the upper right.  \n* Write your blog.  \n* If you want to publish your blog, click the `publish` button in the upper right. If you want to publish it later, Click the `\u003c Posts` button in the upper left, your article should be automatically saved as draft.\n\n## Modify URL\n\nIf you want to change the url edit with \n\n```\nkubectl -n ghost edit ingress ghost-blog\n```\n\nAfter that run deployment patch to update the url env in ghost.\n\nFirst Create file `patch.yaml` using template below :\n\n```yaml\nspec:\n  template:\n    spec:\n      containers:\n      - name: ghost-blog\n        env:\n        - name: url\n          value: CHANGE_WITH_YOUR_NEW_URL\n```\n\nRun the patch command\n\n```\nkubectl -n ghost patch deployment ghost-blog --patch \"$(cat patch.yaml)\"\n```\n\n## Upgrade version\n\nCreate file `patch.yaml` using template below :\n\n```yaml\nspec:\n  template:\n    spec:\n      containers:\n      - name: ghost-blog\n        image: ghost:image_tag\n```\n\nRun the patch command\n\n```\nkubectl -n ghost patch deployment ghost-blog --patch \"$(cat patch.yaml)\"\n```\n\n**NOTE :** You can find the latest image_tag from https://hub.docker.com/_/ghost\n","url":"https://ghost.org/","category":"management","image_url":"https://api.civo.com/k3s-marketplace/ghost.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"15GB","configuration":{"VOLUME_SIZE":{"value":"15Gi"}}}]},{"name":"gitea","title":"Gitea","version":"1.12.5","default":null,"dependencies":null,"maintainer":"@giteaio","description":"Gitea is a community managed lightweight code hosting solution written in Go.","post_install":"## Gitea\n\n### Usage instruction\n\nSee the [documentation](https://gitea.com/gitea/helm-chart/)\n","url":"https://gitea.io","category":"management","image_url":"https://api.civo.com/k3s-marketplace/gitea.png","plans":null},{"name":"haproxy","title":"Haproxy","version":"1.5","default":null,"dependencies":null,"maintainer":"alejandro@civo.com, amit2cha@gmail.com","description":"HAProxy is free, open source software that provides a high availability load balancer and proxy server for TCP and HTTP-based applications.","post_install":"## Haproxy - Ingress controller\n\n### External access to your services\n\nHAProxy is free, open source software that provides a high availability load balancer and proxy server for TCP and HTTP-based applications.To use it for your applications all you have to do is apply a YAML file like the one below to handle ingress:\n\n```yaml\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: yourapp-ingress\n  namespace: default\nspec:\n  rules:\n  - host: www.example.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: service-name\n          servicePort: 8080\n```\n\nThis will open up http://www.example.com (assuming you pointed that non-real domain record to your cluster's IPs) to the whole world.","url":"https://github.com/haproxytech/kubernetes-ingress","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/haproxy.png","plans":null},{"name":"Helm","title":null,"version":"2.16.5","default":null,"dependencies":null,"maintainer":"hello@civo.com","description":"Helm (tiller) helps you define, install, and upgrade even the most complex Kubernetes application.","post_install":"## Helm - The package manager for Kubernetes\n\n### External access\n\nHelm is available to anyone with the credentials to access your Kubernetes cluster.\n\n### Usage instructions\n\nHelm has [very comprehensive documentation](https://helm.sh/docs/) on all things from writing your own charts to installing, upgrading and deleting applications written as Helm charts.\n","url":"https://helm.sh","category":"management","image_url":"https://api.civo.com/k3s-marketplace/helm.png","plans":null},{"name":"Jaeger-Operator","title":null,"version":"1.2.0","default":null,"dependencies":null,"maintainer":"@kaipmdh","description":"Jaeger-Operator is a Kubernetes Operator implementation of the Jaeger Distributed Tracing tool","post_install":"# Running Jaeger\n\nOnce the operator has been installed and deployed, you can start a Jaeger instance by modifying the below snippet for your needs, saving it as jaeger.yaml and running `kubectl apply -f jaeger.yaml`:\n\n```yaml\napiVersion: jaegertracing.io/v1\nkind: Jaeger\nmetadata:\n  name: simplest\n  namespace: observability\n```\n\nYou will then be able to access the Jaeger UI using the IP address of your cluster. This should be displayed when you run `kubectl get -n observability ingress`:\n\n```sh\n$ kubectl get -n observability ingress\nNAME             CLASS    HOSTS   ADDRESS          PORTS   AGE\nsimplest-query   \u003cnone\u003e   *       \u003cip-address\u003e      80      2m\n```\n","url":"https://github.com/jaegertracing/jaeger-operator","category":"monitoring","image_url":"https://api.civo.com/k3s-marketplace/jaeger.png","plans":null},{"name":"Jenkins","title":null,"version":"2.190.1","default":null,"dependencies":["Longhorn"],"maintainer":"@ruanbekker","description":"Jenkins is a Continuous Integration and Delivery server","post_install":"## Jenkins\n\n### External access\n\nBy default external access to the Jenkins UI port isn't available. This is easily changed by applying the following YAML to apply ingress via traefik to your cluster with `kubectl apply -f jenkins-ingress.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: jenkins-ingress\nspec:\n  rules:\n  - host: jenkins.your-cluster-id.k8s.civo.com\n    http:\n      paths:\n      - backend:\n          serviceName: jenkins-frontend\n          servicePort: 8080\n```\n\nThis will open up http://jenkins.YOUR_CLUSTER_ID.k8s.civo.com to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instruction\n\nYou can use this application from within your cluster by just using the hostname `jenkins`, so jenkins agents can use the hostname `jenkins` and the port `50000`. The username and password for jenkins is set via environment variables, `JENKINS_USERNAME` and `JENKINS_PASSWORD` using the username and password presented in the Web UI and CLI.\n","url":"https://jenkins.io","category":"ci_cd","image_url":"https://api.civo.com/k3s-marketplace/jenkins.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]},{"name":"Joomla","title":null,"version":"3.9.24","default":null,"dependencies":["longhorn","mariadb:5GB","cert-manager"],"maintainer":"keith@hubner.co.uk, amit2cha@gmail.com","description":"Popular open source content management system (CMS)","post_install":"## Joomla \n\n### Usage instructions\n\n### DB Setup\nBefore running the setup wizard you will need to create a database and user account in mariadb\n\n```\n$ kubectl exec -it svc/mariadb -- /bin/sh\n\n# mysql -u root -p\nEnter password: YOUR_ROOT_PASSWORD_HERE\n\nMariaDB [(none)]\u003e CREATE DATABASE joomla_db;\nMariaDB [(none)]\u003e CREATE USER joomla_user identified by 'strong-password';\nMariaDB [(none)]\u003e GRANT ALL ON joomla_db.* TO joomla_user;\n```\n\n### External Access\n\nAn ingress is automatically created during the application install. A certificate using cert manager and lets-encrypt is also applied automatically and registered against your Civo email address and the generated domain name.\n\nYou can access this (replacing the clusterID with your own) via: https://joomla.YOUR_CLUSTER_ID.k8s.civo.com\n\n###\nYou should now see the setup page where you can enter the database details created above.\n\u003e Note the database server is called mariadb\n\n\n\n\n","url":"https://www.joomla.org/","category":"management","image_url":"https://api.civo.com/k3s-marketplace/joomla.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]},{"name":"keptn","title":null,"version":"0.7.1","default":null,"dependencies":null,"maintainer":"sangambiradar@hotmail.com","description":"an event-based control plane for continuous delivery and automated operations for cloud-native applications.","post_install":"\n## Keptn\n\n### Start using Keptn\n\n1. Download the Keptn CLI: \n  ```\n  curl -sL https://get.keptn.sh | sudo -E bash\n  ```\n\n1. Before you connect your CLI to your Keptn installation in Civo, make sure that Keptn is ready.\n\n  ```\n  kubectl get deploy -n keptn\n  ```\n\n  If all deployments are ready and available, please proceed to the next step.\n\n\n1. Connect the CLI to the Keptn installation\n  ```\n  API_PORT=$(kubectl get svc api-gateway-nginx -n keptn -o jsonpath='{.spec.ports[?(@.name==\"http\")].nodePort}')\n  EXTERNAL_NODE_IP=$(kubectl get nodes -o jsonpath='{ $.items[0].status.addresses[?(@.type==\"ExternalIP\")].address }')\n  KEPTN_ENDPOINT=http://${EXTERNAL_NODE_IP}:${API_PORT}/api\n  KEPTN_API_TOKEN=$(kubectl get secret keptn-api-token -n keptn -ojsonpath={.data.keptn-api-token} | base64 --decode)\n\n  keptn auth --endpoint=$KEPTN_ENDPOINT --api-token=$KEPTN_API_TOKEN\n  ```\n\n1. Access the bridge via:\n  ```\n  echo http://${EXTERNAL_NODE_IP}:${API_PORT}/bridge\n  ```\n  \n  Get the credentials with the following command:\n  ```\n  keptn configure bridge -o\n  ```\n\n1. Follow the [tutorials](https://tutorials.keptn.sh/?cat=quality-gates) to get started! Please note that Keptn is already installed and these parts of the tutorials can be skipped :)\n\n\n\n## Documentation and tutorials\n\n- Find more information in the [Keptn documentation](https://keptn.sh/docs).\n- Check out the [Keptn tutorials](https://tutorials.keptn.sh/?cat=quality-gates) that help you get started with different use-cases.\n","url":"https://keptn.sh/","category":"ci_cd","image_url":"https://api.civo.com/k3s-marketplace/keptn.png","plans":null},{"name":"kube-hunter","title":null,"version":"latest","default":null,"dependencies":null,"maintainer":"@milindchawre","description":"kube-hunter is an open-source tool that hunts for security issues in your Kubernetes clusters.","post_install":"## Using kube-hunter\n\n### Usage instruction\n\nHere we run kube-hunter in a pod within the cluster. This gives an indication of how exposed your cluster would be in the event that one of your application pods is compromised (through a software vulnerability, for example).\n\nCheck the logs of the kube-hunter pod to see the results.\n```\n# Get the pod name\n$ kubectl -n kube-hunter describe job kube-hunter\n# Check the logs\n$ kubectl -n kube-hunter logs \u003cpod name\u003e\n```\n\nWhen the kube-hunter reports an issue, it will show its VID (Vulnerability ID) in the pod logs. You can further explore about that vulnerability by putting the VID on [this site](https://aquasecurity.github.io/kube-hunter/).\n\nIf you want to run kube-hunter on daily basis, feel free to convert it to a [cronjob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/).\n\nTo know more, check this [official guide](https://github.com/aquasecurity/kube-hunter).\n","url":"https://github.com/aquasecurity/kube-hunter","category":"security","image_url":"https://api.civo.com/k3s-marketplace/kube-hunter.png","plans":null},{"name":"kube-scan","title":null,"version":"v20.5","default":null,"dependencies":null,"maintainer":"@milindchawre","description":"Kube-scan is risk assessment tool for your kubernetes cluster.","post_install":"## Using kube-scan\n\n### Usage instruction\n\nWe use `kubectl port-forward` to expose kube-scan UI.\n```\nkubectl port-forward --namespace kube-scan svc/kube-scan-ui 8080:80\n```\nNow access the kube-scan UI at `http://localhost:8080`\n\nTo know more, check the [official guide](https://github.com/octarinesec/kube-scan).\n","url":"https://github.com/octarinesec/kube-scan","category":"security","image_url":"https://api.civo.com/k3s-marketplace/kube-scan.png","plans":null},{"name":"Kubei","title":null,"version":"1.0.7","default":null,"dependencies":null,"maintainer":"@milindchawre","description":"Kubei is a vulnerabilities scanning tool that allows users to get an accurate and immediate risk assessment of their kubernetes clusters.","post_install":"## Using Kubei\n\n### Usage instruction\n\nVerify Kubei is up and running.\n```\n$ kubectl -n kubei get pod -lapp=kubei\nNAME                     READY   STATUS    RESTARTS   AGE\nkubei-5f7564c946-8rsvj   1/1     Running   0          4m\n```\n\nWe use `kubectl port-forward` to expose Kubei UI.\n```\n$ kubectl -n kubei port-forward $(kubectl -n kubei get pods -lapp=kubei -o jsonpath='{.items[0].metadata.name}') 8080\n```\nNow access the Kubei UI at `http://localhost:8080/view` and then click `GO` to run a scan.\n\nTo check the state of Kubei, and the progress of ongoing scans, run the following command:\n```\n$ kubectl -n kubei logs $(kubectl -n kubei get pods -lapp=kubei -o jsonpath='{.items[0].metadata.name}')\n```\n\nRefresh the page `http://localhost:8080/view` to see the updated results.\n\nTo know more, check the [official guide](https://github.com/Portshift/Kubei).\n","url":"https://github.com/Portshift/Kubei","category":"security","image_url":"https://api.civo.com/k3s-marketplace/kubei.png","plans":null},{"name":"Kubeless","title":null,"version":"1.0.5","default":null,"dependencies":null,"maintainer":"@gilsdav","description":"Kubeless is a Kubernetes-native serverless framework that lets you deploy small bits of code without having to worry about the underlying infrastructure.","post_install":"## Kubeless\n\n### UI External access\n\nBy default external access to the Kubeless UI isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f kubeless-ingress.yaml` (or whatever you call the file containing the contents below):\n\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ui\n  namespace: kubeless\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: ui.kubeless.\u003cclusterDomainName\u003e\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: ui\n          servicePort: ui-port\n```\n\n\nThis will open up `http://ui.kubeless.\u003cclusterDomainName\u003e` to the whole world.\n\n### Functions External access\n\nBy default external access to the functions isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f kubeless-functions-ingress.yaml` (or whatever you call the file containing the contents below):\n\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: functions\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: functions.default.\u003cclusterDomainName\u003e\n    http:\n      paths:\n      - path: /\u003cfunctionName1\u003e\n        backend:\n          serviceName: \u003cfunctionName1\u003e\n          servicePort: 8080\n      - path: /\u003cfunctionName2\u003e\n        backend:\n          serviceName: \u003cfunctionName2\u003e\n          servicePort: 8080\n```\n\nThis will open up\n\n* `http://functions.default.\u003cclusterDomainName\u003e/\u003cfunctionName1\u003e`\n* `http://functions.default.\u003cclusterDomainName\u003e/\u003cfunctionName2\u003e`\n\nto the whole world.\n\n#### Update\nThe same creation `apply` command can be used to update ingress configuration after adding a new function path.\n","url":"https://kubeless.io/","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/kubeless.png","plans":null},{"name":"Kubenav","title":null,"version":"3.1.0","default":null,"dependencies":null,"maintainer":"@si458","description":"kubenav is the navigator for your Kubernetes clusters right in your browser","post_install":"## Kubenav\n\n### Accessing the dashboard\n\nThe Kubenav UI is only accessible inside the cluster via its ClusterIP\n\nso you need to proxy into the cluster by running:\n\n```\nkubectl port-forward --namespace kubenav svc/kubenav 14122\n```\n\nThe Kubenav UI will now be accessible at the following url:\n\nhttp://localhost:14122\n","url":"https://docs.kubenav.io","category":"management","image_url":"https://api.civo.com/k3s-marketplace/kubenav.png","plans":null},{"name":"kubernetes-dashboard","title":"Kubernetes Dashboard","version":"v2.0.0","default":null,"dependencies":null,"maintainer":"morgan.lane@outlook.com","description":"Kubernetes Dashboard provides a UI for interacting and managing Kubernetes clusters","post_install":"## Kubernetes Dashboard\n\n### Accessing the dashboard\n\nIn order to access the dashboard, you must obtain the bearer token for the admin service account. To do this, run the following command:\n\n```\nkubectl -n kubernetes-dashboard describe secret admin-user-token | grep ^token\n```\n\nOnce you have that token, you can proxy into the cluster by running:\n\n```\nkubectl proxy\n```\n\nThe dashboard will now be accessible at the following url:\n\nhttp://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/\n\nTo access it, enter the token you obtained by selecting \"Sign In\" and \"Bearer Token\".\n\nYou will now have access to the dashboard!\n","url":"https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/","category":"management","image_url":"https://api.civo.com/k3s-marketplace/kubernetes-dashboard.png","plans":null},{"name":"Kubevious","title":null,"version":"v0.8.15","default":null,"dependencies":null,"maintainer":"@saiyampathak","description":"open-source software that provides a usable and highly graphical interface for Kubernetes","post_install":"## Kubevious Helm chart will deploy the ingress as well and the dashboard can be accessed via traefik port\n\napply the ingress with below contents for external access \n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: kubevious\n  namespace: kubevious\nspec:\n  rules:\n  - host: kubevious.\u003cyour-cluster-id\u003e.k8s.civo.com\n    http:\n      paths:\n      - backend:\n          serviceName: kubevious-ui-nodeport\n          servicePort: 80\n          \n```\nThis will open up http://kubevious.YOUR_CLUSTER_ID.k8s.civo.com to the whole world.\n\n       \n","url":"https://github.com/kubevious/kubevious","category":"management","image_url":"https://api.civo.com/k3s-marketplace/kubevious.png","plans":null},{"name":"Linkerd","title":null,"version":"Latest","default":null,"dependencies":null,"maintainer":"hello@civo.com","description":"Linkerd is a service mesh, giving you runtime debugging, observability, reliability, and security.","post_install":"## Linkerd service mesh\n\n### External access\n\nThe Linkerd dashboard is not available to the public by default, but if you install the linkerd client utility, you can open a tunnel to it easily:\n\n```\ncurl -sL https://run.linkerd.io/install | sh\n# or brew install linkerd on macOS\n\nlinkerd dashboard\n```\n\nThis will automatically open the Linkerd dashboard in your browser, or you can visit http://127.0.0.1:50750\n\n### Usage instructions\n\nLinkerd provides instructions on [installing a demo application](https://linkerd.io/2/getting-started/#step-5-install-the-demo-app) that uses Linkerd on their site. It's worth a read and a play with service meshes to get the hang of how/when they are of benefit.\n","url":"https://linkerd.io","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/linkerd.png","plans":null},{"name":"LitmusChaos","title":null,"version":"1.13.0","default":null,"dependencies":null,"maintainer":"gdsoumya@chaosnative.com, sayan@chaosnative.com","description":"LitmusChaos is a cloud-native Chaos Engineering framework","post_install":"## Using LitmusChaos Operator \n\n- Verify that the chaos operator and chaos CRDs are successfully installed\n\n  ```\n  $ kubectl get pods -n litmus\n  NAME                                 READY   STATUS    RESTARTS   AGE\n  chaos-operator-ce-56449c7d75-lt8jc   1/1     Running   0          90s\n  ```\n\n  ```\n  $ kubectl get crds | grep chaos\n\n  chaosengines.litmuschaos.io       2020-11-06T14:23:59Z\n  chaosexperiments.litmuschaos.io   2020-11-06T14:24:00Z\n  chaosresults.litmuschaos.io       2020-11-06T14:24:00Z\n  ```\n\n  ```\n  $ kubectl api-resources | grep chaos\n  chaosengines                                   litmuschaos.io                 true         ChaosEngine\n  chaosexperiments                               litmuschaos.io                 true         ChaosExperiment\n  chaosresults                                   litmuschaos.io                 true         ChaosResult\n  ```\n\n\n- Refer to the litmuschaos documentation for detailed steps on how you can execute different chaos experiments: https://docs.litmuschaos.io.\n  You can also refer to this [blog](https://www.civo.com/learn/chaos-engineering-kubernetes-litmus) to get started with litmus on Civo Cloud.\n","url":"https://github.com/litmuschaos/litmus","category":"ci_cd","image_url":"https://api.civo.com/k3s-marketplace/litmuschaos.png","plans":null},{"name":"loki-stack","title":"Loki Stack ","version":"v0.41.2","default":null,"dependencies":["prometheus-operator"],"maintainer":"me@r15cookie.com","description":"Prometheus for your logs.","post_install":"## Post Install\n\n- Port forward to the grafana pod\n```sh\nkubectl port-forward -n monitoring service/prometheus-operator-grafana 8080:80\n```\n- Log into the grafana stack \n  - URL: http://localhost:8080 \n  - credentials: admin/prom-operator\n- Go to \"Configuration\" (gear icon along left hand side), then \"Data Sources\"\n- Click \"Add Data Source\"\n- Select Loki\n- Set URL to `http://loki.loki.svc.cluster.local:3100`\n- Save and Test Source\n- Grafana's \"Explorer\" functionality can be used to get a quick view of collected logs.\n","url":"https://grafana.com/oss/loki/","category":"monitoring","image_url":"https://api.civo.com/k3s-marketplace/loki.png","plans":null},{"name":"Longhorn","title":null,"version":"1.1.0","default":null,"dependencies":null,"maintainer":"hello@civo.com","description":"Longhorn is a lightweight, reliable, and powerful distributed block storage system for Kubernetes.","post_install":"## Using Longhorn persistent volumes\n\n### Installation note:\n\nLonghorn requires a minimum of 3 nodes to function, if you attempt to install Longhorn on cluster smaller than this, it will not function properly. If you have installed Longhorn on a cluster that is too small, you will encounter errors from Longhorn, but you can simply scale the cluster up to a 3 node minimum and the issue will resolve itself automatically.\n\n### External access\n\nBy default external access to the Longhorn dashboard isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f longhorn-service.yaml` (or whatever you call the file containing the contents below):\n\n\n```yaml\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    app: longhorn-ui\n  name: longhorn-frontend\n  namespace: longhorn-system\nspec:\n  selector:\n    app: longhorn-ui\n  ports:\n  - port: 8000\n    targetPort: 8000\n  type: LoadBalancer\n```\n\nThis will open up http://YOUR_CLUSTER_ID.k8s.civo.com:8000/dashboard to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instructions\n\nLonghorn will be set as the default storage class.  As such, and PersistentVolumeClaim (pvc) will automatically have storage provisioned with Longhorn's defaults.  An example of such a request would be:\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysql-simple\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n```\n\nIf you want to have more control over the longhorm volume properties (replica count, etc), create the PersistentVolume first.  An example such as `pv.yaml` could be used:\n\n```yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: mysql-pv\n  labels:\n    name: mysql-data\n    type: longhorn\nspec:\n  capacity:\n    storage: 5Gi\n  volumeMode: Filesystem\n  storageClassName: longhorn\n  accessModes:\n    - ReadWriteOnce\n  csi:\n    driver: io.rancher.longhorn\n    fsType: ext4\n    volumeAttributes:\n      numberOfReplicates: '2'\n      staleReplicaTimeout: '20'\n    volumeHandle: mysql-data\n```\n\nAnd create a claim to that volume (like an abstract request so that something can use the volume) in something like `pv-claim.yaml`:\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysql-pv-claim\n  labels:\n    type: longhorn\n    app: example\nspec:\n  storageClassName: longhorn\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n```\n","url":"https://github.com/longhorn/longhorn","category":"storage","image_url":"https://api.civo.com/k3s-marketplace/longhorn.png","plans":null},{"name":"Maesh","title":null,"version":"Latest","default":null,"dependencies":["Helm"],"maintainer":"hello@civo.com","description":"Maesh is an easy to configure and non-invasive service mesh that allows visibility and management of the traffic flows.","post_install":"## Maesh - a straight-forward, easy to configure, and non-invasive service mesh\n\n### Usage instruction\n\nYou configure your services to use Maesh with a simple annotation. For more instructions on configuring your services to use Maesh see [their website](https://docs.mae.sh/configuration/).","url":"https://mae.sh","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/maesh.png","plans":null},{"name":"MariaDB","title":null,"version":"10.4.7","default":null,"dependencies":["Longhorn"],"maintainer":"hello@civo.com","description":"MariaDB is a community-developed fork of MySQL intended to remain free under the GNU GPL.","post_install":"## MariaDB - MySQL compatible database\n\n### External access\n\nBy default external access to the MariaDB port isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f mariadb-service.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 3306\n      targetPort: 3306\n      protocol: TCP\n  selector:\n    app: mariadb\n```\n\nThis will open up http://YOUR_CLUSTER_ID.k8s.civo.com:3306 to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instruction\n\nYou can use this application from within your cluster by just using the hostname `mariadb` and can create databases and users using the `root` access credentials above this message. For example, to create an application's database and user credentials and given that the `kubectx` and [Civo CLI](https://github.com/civo/cli) are installed, with a Civo Kubernetes cluster called `my-cluster-name`:\n\n```\n$ civo k3s config my-cluster-name --save\n$ kubectx my-cluster-name\n$ kubectl run tmp-shell --generator=run-pod/v1 --rm -i \\\n  --tty --image alpine -- /bin/sh\n\n/ # apk update\n/ # apk add mariadb-client\n/ # mysql -u root -pYOUR_ROOT_PASSWORD_HERE -h mariadb\n\nmysql\u003e CREATE DATABASE my_application;\nmysql\u003e GRANT ALL ON my_application.* to my_user identified \n       by 'super-strong-password-here';\n```\n","url":"https://mariadb.com","category":"database","image_url":"https://api.civo.com/k3s-marketplace/mariadb.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]},{"name":"metrics-server","title":"Metrics Server","version":"(default)","default":true,"dependencies":null,"maintainer":"@Rancher_Labs","description":"Metrics Server is a cluster-wide aggregator of resource usage data.","post_install":"## Metrics Server - provide metrics for Kubernetes HPAv2 (Pod auto-scaling)\n\n### Test it out\n\nCheck that data is being received from nodes:\n\n```\nkubectl get --raw \"/apis/metrics.k8s.io/v1beta1/nodes\"\n```\n\nCheck node usage:\n\n```sh\nkubectl top node\n```\n\nCheck node usage:\n\n```sh\nkubectl top pod --all-namespaces\n```\n\n### Usage instruction\n\nSee the Kubernetes documentation for a worked-example of how to use HPAv2.\n\n[Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)\n\nYou can also see the OpenFaaS documentation for a detailed tutorial.\n\n* [OpenFaaS - install the metrics server](https://docs.openfaas.com/tutorials/kubernetes-hpa/#install-the-metrics-server)\n","url":"https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/metrics-server.png","plans":null},{"name":"MinIO","title":null,"version":"2019-08-29","default":null,"dependencies":["Longhorn"],"maintainer":"hello@civo.com","description":"Minio is an Amazon S3 compatible object storage server.","post_install":"## Using MinIO for S3 compatible object storage\n\n### External access\n\nBy default external access to the MinIO UI isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f minio-service.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: minio-service\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 9000\n      targetPort: 9000\n      protocol: TCP\n  selector:\n    app: minio\n```\n\nThis will open up http://YOUR_CLUSTER_ID.k8s.civo.com:9000 to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instruction\n\nWe'd recommend installing [mc](https://github.com/minio/mc) the MinIO client for your operating system, to allow easy file operations from the command line.\n\nOther than that, your access key and secret key should be above this message and you can use those to configure your application to access MinIO just as you would with S3. For example, Ruby on Rails ActiveStorage is configured with something like:\n\n```\nminio:\n  service: S3\n  access_key_id: YOUR_ACCESS_KEY_HERE\n  secret_access_key: YOUR_SECRET_KEY_HERE\n  region: us-east-1\n  bucket: your_own_bucket\n  endpoint: \"http://YOUR_CLUSTER_ID.k8s.civo.com:9000\"\n  force_path_style: true\n```\n\nWe would also recommend installing TLS certificates and using the pre-installed Traefik as an Ingress controller.\n","url":"https://min.io","category":"storage","image_url":"https://api.civo.com/k3s-marketplace/minio.png","plans":[{"label":"5GB","configuration":{"PV_SIZE_GB":{"value":"5Gi"}}},{"label":"10GB","configuration":{"PV_SIZE_GB":{"value":"10Gi"}}},{"label":"20GB","configuration":{"PV_SIZE_GB":{"value":"20Gi"}}}]},{"name":"MongoDB","title":null,"version":"4.2.12","default":null,"dependencies":["Longhorn"],"maintainer":"hello@civo.com","description":"MongoDB document databases provide high availability and easy scalability.","post_install":"## MongoDB\n\n### External access\n\nBy default external access to the MongoDB port isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f mongodb-service.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mongodb-service\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 27017\n      targetPort: 27017\n      protocol: TCP\n  selector:\n    app: mongodb\n```\n\nThis will open up YOUR_CLUSTER_ID.k8s.civo.com:27017 to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instruction\n\nYou can use this application from within your cluster by just using the hostname `mongodb` and can create databases and users using the `root` access credentials above this message. For example, to create an application's database and user credentials and given that the `kubectx` and [Civo CLI](https://github.com/civo/cli) are installed, with a Civo Kubernetes cluster called `my-cluster-name`:\n\n```\n$ civo k3s config my-cluster-name --save\n$ kubectx my-cluster-name\n$ kubectl run tmp-shell --generator=run-pod/v1 --rm -i \\\n  --tty --image alpine:3.9 -- /bin/sh\n\n/ # apk update\n/ # apk add mongodb\n/ # mongo mongodb://root:password@mongodb:27017/test?authSource=admin\n\n\u003e use people\nswitched to db people\n\u003e db.collection1.insert({\"name\": \"ruan\", \"surname\": \"bekker\"})\nWriteResult({ \"nInserted\" : 1 })\n\u003e db.collection1.find().pretty()\n{\n\t\"_id\" : ObjectId(\"5d9dc2bd8d1d65fd1e25f41b\"),\n\t\"name\" : \"ruan\",\n\t\"surname\" : \"bekker\"\n}\n```\n","url":"https://www.mongodb.com","category":"database","image_url":"https://api.civo.com/k3s-marketplace/mongodb.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]},{"name":"Netdata","title":null,"version":"Latest","default":null,"dependencies":["Helm"],"maintainer":"@milindchawre","description":"Netdata is distributed, real-time performance and health monitoring for systems and applications.","post_install":"## Using netdata\n\n### Usage instruction\n\nWe use `kubectl port-forward` to expose netdata UI.\n```\nkubectl port-forward deployment/netdata-parent -n netdata 19999:19999\n```\nNow access the netdata UI at `http://localhost:19999`\n\nTo know more, check the [official guide](https://learn.netdata.cloud/guides/monitor/kubernetes-k8s-netdata). Also check their [github README](https://github.com/netdata/netdata).\n","url":"https://github.com/netdata/netdata","category":"monitoring","image_url":"https://api.civo.com/k3s-marketplace/netdata.png","plans":null},{"name":"NextCloud","title":null,"version":"20.0.7","default":null,"dependencies":["longhorn","mariadb:5GB","cert-manager"],"maintainer":"keith@hubner.co.uk, amit2cha@gmail.com","description":"Nextcloud is a completely integrated self-managed content collaboration platform","post_install":"## NextCLoud - The self-hosted productivity platform\n\n### Usage instructions\n\n### DB Setup\nBefore running the setup wizard you will need to create a database and user account in mariadb\n\n```\n$ kubectl exec -it svc/mariadb -- /bin/sh\n\n# mysql -u root -p\nEnter password: YOUR_ROOT_PASSWORD_HERE\n\nMariaDB [(none)]\u003e CREATE DATABASE nextcloud_db;\nMariaDB [(none)]\u003e CREATE USER nc_user identified by 'strong-password';\nMariaDB [(none)]\u003e GRANT ALL ON nextcloud_db.* TO nc_user;\n```\n\n### External Access\n\nAn ingress is automatically created during the application install. A certificate using cert manager and lets-encrypt is also applied automatically and registered against your Civo email address and the generated domain name.\n\nYou can access this (replacing the clusterID with your own) via: https://nextcloud.YOUR_CLUSTER_ID.k8s.civo.com\n\n###\nYou should now see the setup page where you can enter the database details created above.\n\u003e Note the database server is called mariadb\n\n\n\n\n","url":"https://nextcloud.com/","category":"management","image_url":"https://api.civo.com/k3s-marketplace/nextcloud.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]},{"name":"Nginx","title":null,"version":"latest","default":null,"dependencies":null,"maintainer":"@Saiyam Pathak","description":"ingress-nginx is an Ingress controller for Kubernetes using NGINX as a reverse proxy and load balancer.","post_install":"## Nginx ingress controller\n\n### External access to your services\n\ningress-nginx is an Ingress controller for Kubernetes using NGINX as a reverse proxy and load balancer. To use it for your applications all you have to do is apply a YAML file like the one below to handle ingress:\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: yourapp-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\nspec:\n  rules:\n  - host: www.example.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: yourapp-service\n          servicePort: http\n```\n\nThis will open up http://www.example.com (assuming you pointed that non-real domain record to your cluster's IPs) to the whole world.\n\n","url":"https://kubernetes.github.io/ingress-nginx/","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/nginx.png","plans":null},{"name":"Node-RED","title":null,"version":"1.2.7","default":null,"dependencies":["longhorn"],"maintainer":"javicv@gmail.com","description":"Node-RED is a programming tool for wiring together hardware devices, APIs and online services in new and interesting ways.","post_install":"# Node-RED\n\n## External Access\n\nAn Ingress is created during the installation process. To access your Node-RED use http://nodered.YOUR_CLUSTER_ID.k8s.civo.com\n\nIf you want to change the hostname or modify the ingress, edit it with\n\n```\nkubectl edit ingress nodered\n```\n\n**There is no user authentication by default**, please consider, at least, using Basic Authentication to protect your Node-RED instance.\n\n## Documentation\n\nYou can find documentation, tutorials, recipes and more in \u003chttps://nodered.org/docs/\u003e\n\n## Library\n\nDon't Repeat Yourself, visit \u003chttps://flows.nodered.org/\u003e to find nodes and flows developed by other people or to share yours.\n","url":"https://nodered.org/","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/nodered.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]},{"name":"OpenFaaS","title":null,"version":"0.18.0","default":null,"dependencies":["Helm"],"maintainer":"@openfaasltd","description":"OpenFaaS makes it easy for developers to deploy event-driven functions and microservices to Kubernetes without repetitive, boiler-plate coding.","post_install":"## OpenFaaS\n\nThank you for deploying [OpenFaaS](https://github.com/openfaas/faas) to Civo's k3s service.\n\n## Obtain access\n\nThe OpenFaaS gateway has been made available through a `NodePort` on port `31112` on each node.\n\n* Go to your Civo dashboard, click Kubernetes and then your OpenFaaS Cluster.\n\nLook for the DNS entry that you find there, it may look something like `6c1c1646-25cf-44f0-9bd5-53ee35cd7c84.k8s.civo.com`\n\nThis DNS record which points at each of the nodes in your cluster.\n\n* Set the following URL:\n\n```sh\nexport DNS=\"\" # As per dashboard\nexport OPENFAAS_URL=http://$DNS:31112\n```\n\n### Get your kubeconfig\n\nPick A or B:\n\n* A) Get your kubeconfig via command-line\n\n    ```sh\n    civo k8s ls\n\n    civo k8s kubeconfig --save \u003cCLUSTER_NAME\u003e\n\n    kubectl config set-context \u003cCLUSTER_NAME\u003e\n    ```\n\n* B) Get your kubeconfig via the Dashboard\n\n    Download your `kubeconfig` file from the Civo dashboard.\n\n    Now set the `KUBECONFIG` environment variable, so that you point at your new cluster:\n\n    ```\n    export KUBECONFIG=$HOME/Downloads/config-file.yaml\n    ```\n\n### Find your generated password\n\nYou can find your password above and save it as `password.txt`.\n\nAlternative, retrieve the password using `kubectl`:\n\n```\necho $(kubectl get secret -n openfaas basic-auth -o jsonpath=\"{.data.basic-auth-password}\" | base64 --decode; echo) \u003e password.txt\n```\n\n### Use the CLI to log in\n\nNow install the [faas-cli](http://github.com/openfaas/faas-cli) and log in:\n\n```\ncat password.txt | faas-cli login --username admin --password-stdin\n```\n\n### Deploy a test function\n\n```\nfaas-cli store list\n\n# Find one you like\n\nfaas-cli store deploy nodeinfo\n\n# List your functions\n\nfaas-cli list --verbose\n\n# Check when the function is ready\n\nfaas-cli describe nodeinfo\n\nName:                nodeinfo\nStatus:              Ready\n\n# Invoke the function using the URL given above, or via `faas-cli invoke`\n\necho | faas-cli invoke nodeinfo\necho -n \"verbose\" | faas-cli invoke nodeinfo\n```\n\n### Access the OpenFaaS Gateway UI\n\nYou can now use the DNS entry you found earlier in a web-browser to access your dashboard.\n\n```sh\necho $OPENFAAS_URL\n```\n\n## Next steps\n\n* Read the docs: [Deploy TLS with LetsEncrypt to enable HTTPS](https://docs.openfaas.com/reference/ssl/kubernetes-with-cert-manager/)\n\n* Learn OpenFaaS: [Try The Official Workshop](https://github.com/openfaas/workshop)\n\n* Get help: Join the [OpenFaaS Slack](https://slack.openfaas.io/)\n","url":"https://www.openfaas.com/","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/openfaas.png","plans":null},{"name":"permission-manager","title":null,"version":"1.6.0","default":null,"dependencies":null,"maintainer":"@milindchawre","description":"Permission Manager provides an easy and user-friendly mechanism for managing RBAC in Kubernetes.","post_install":"## Using Permission Manager\n\n### Usage instructions\n\nUse `kubectl port-forward` to expose Permission Manager UI.\n```\nkubectl port-forward --namespace permission-manager svc/permission-manager 4000:4000\n```\nNow access the Permission Manager UI at `http://localhost:4000`\n\nYou will be prompted for username and password. Use `admin` as username and get the password from below command.\n```\nkubectl get secret -n permission-manager permission-manager -o=jsonpath='{.data.BASIC_AUTH_PASSWORD}' | base64 --decode\n```\nTo know more how to use it, check their [official guide](https://github.com/sighupio/permission-manager).\n","url":"https://github.com/sighupio/permission-manager","category":"management","image_url":"https://api.civo.com/k3s-marketplace/permission-manager.png","plans":null},{"name":"Polaris","title":null,"version":"1.2.0","default":null,"dependencies":null,"maintainer":"@milindchawre","description":"Polaris identifies Kubernetes deployment configuration errors that can cause security vulnerabilities, outages, scaling limitations and more.","post_install":"## Using Polaris\n\n### Usage instruction\n\nWe use `kubectl port-forward` to expose Polaris UI.\n```\nkubectl port-forward --namespace polaris svc/polaris-dashboard 8080:80\n```\nNow access the Polaris UI at `http://localhost:8080`\n\nTo know more how to use it, check this [civo learning guide for polaris](https://www.civo.com/learn/setting-up-polaris-on-k8s).\n","url":"https://www.fairwinds.com/polaris","category":"security","image_url":"https://api.civo.com/k3s-marketplace/polaris.png","plans":null},{"name":"Portainer","title":null,"version":"ce","default":null,"dependencies":null,"maintainer":"@saiyampathak","description":"An open source kubernetes management platform","post_install":"## Portainer for kubernetes management\n\n### External access\n\nBy default external access to the Portainer isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f portainer-ingress.yaml` (or whatever you call the file containing the contents below):\n\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: portainer\n  namespace: portainer\nspec:\n  rules:\n  - host: portainer.\u003cyour-cluster-id\u003e.k8s.civo.com\n    http:\n      paths:\n      - backend:\n          serviceName: portainer\n          servicePort: 9000\n```\n\n\nThis will open up http://portainer.YOUR_CLUSTER_ID.k8s.civo.com to the whole world.\n","url":"https://portainer.io","category":"management","image_url":"https://api.civo.com/k3s-marketplace/portainer.png","plans":null},{"name":"PostgreSQL","title":null,"version":"11.5","default":null,"dependencies":["Longhorn"],"maintainer":"hello@civo.com","description":"The PostgreSQL object-relational database system provides reliability and data integrity.","post_install":"## PostgreSQL - reliable SQL database\n\n### External access\n\nBy default external access to the PostgreSQL port isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f postgresql-service.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgresql-service\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 5432\n      targetPort: 5432\n      protocol: TCP\n  selector:\n    app: postgresql\n```\n\nThis will open up http://YOUR_CLUSTER_ID.k8s.civo.com:5432 to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instruction\n\nYou can use this application from within your cluster by just using the hostname `postgresql` and can create databases and users using the admin access credentials above this message. For example, to create an application's database and user credentials and given that the `kubectx` and [Civo CLI](https://github.com/civo/cli) are installed, with a Civo Kubernetes cluster called `my-cluster-name`:\n\n```\n$ civo k3s config my-cluster-name --save\n$ kubectx my-cluster-name\n$ kubectl run tmp-shell --generator=run-pod/v1 --rm -i \\\n  --tty --image alpine -- /bin/sh\n\n/ # apk update\n/ # apk add postgresql-client\n/ # psql -U ADMIN_USERNAME -h postgresql postgresdb\nPassword for user 12CNT2Eq6i: \npsql (11.5)\nType \"help\" for help.\n\npostgresdb=# CREATE DATABASE yourdbname;\npostgresdb=# CREATE USER youruser WITH ENCRYPTED PASSWORD 'super-strong-password';\npostgresdb=# GRANT ALL PRIVILEGES ON DATABASE yourdbname TO youruser;\n```\n","url":"https://www.postgresql.org","category":"database","image_url":"https://api.civo.com/k3s-marketplace/postgresql.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]},{"name":"prometheus-operator","title":"Prometheus Operator","version":"0.35.0","default":null,"dependencies":null,"maintainer":"@puck","description":"Prometheus Operator App install prometheus, alertmanager, grafana and other tools to monitor your kubernetes cluster.","post_install":"# Prometheus-Operator\n\nThe [prometheus-operator](https://github.com/coreos/prometheus-operator) \ncreates/configures/manages Prometheus clusters atop Kubernetes.\n\n## Details\n\nThe prometheus-operator stack is installed in the `monitoring` namespace, to check the pods/services installed use:\n```sh\nkubectl get pods -n monitoring\nkubectl get services -n monitoring\n```\n\nThe installed services are:\n* prometheus-operator\n* prometheus\n* alertmanager\n* node-exporter\n* kube-state-metrics\n* grafana\n\nService monitors to scrape internal kubernetes components:\n* kube-apiserver\n* kube-scheduler\n* kube-controller-manager\n* etcd\n* kube-dns/coredns\n* kube-proxy\n\n\nFor further details on this specific installation please see the [Helm chart](https://github.com/helm/charts/tree/master/stable/prometheus-operator).\n\n## Configuration\n\nVisit [prometheus-operator](https://github.com/coreos/prometheus-operator) to learn how to configure Prometheus \u0026 Alertmanager.\n","url":"https://github.com/coreos/prometheus-operator","category":"monitoring","image_url":"https://api.civo.com/k3s-marketplace/prometheus-operator.png","plans":null},{"name":"RabbitMQ","title":null,"version":"3.8.8-management","default":null,"dependencies":null,"maintainer":"habil@bozali.com","description":"RabbitMQ is an open-source message-broker software that originally implemented the Advanced Message Queuing Protocol.","post_install":"## RabbitMQ\n\n### External access\n\nBy default external access to the RabbitMQ port isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f rabbit-mq.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: rabbitmq\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: rabbit.\u003cclusterDomainName\u003e\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: rabbitmq\n          servicePort: 15672\n```\n\nThis will open up http://rabbit.\u003cclusterDomainName\u003e to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instructions\n\nDefault username : guest\nDefault password : guest\n\nNote: Don't forget the change default username and password or lock down url with firewall.\n","url":"https://www.rabbitmq.com/","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/rabbitmq.png","plans":null},{"name":"Rancher","title":null,"version":"v2.5.0","default":null,"dependencies":null,"maintainer":"@saiyampathak","description":"Addresses the operational and security challenges of managing multiple Kubernetes clusters with integrated tools for running containerized workloads.","post_install":"## Rancher - with Civo k3s cluster imported\n\n### External access\n\nBy default external access to the Rancher isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f rancher-ingress.yaml` (or whatever you call the file containing the contents below):\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: cattle-ingress\n  namespace: cattle-system\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: rancher.\u003cyour-cluster-id\u003e.k8s.civo.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n             name: cattle-service\n             port:\n               name: http\n```\n\nIf you are using a NGINX ingress, simply change `kubernetes.io/ingress.class` to `nginx`.\n\nThis will open up https://\u003cmasterIP\u003e:\u003ctraefik443PORT\u003e to the whole world.\n","url":"https://rancher.com/","category":"management","image_url":"https://api.civo.com/k3s-marketplace/rancher.png","plans":null},{"name":"Redis","title":null,"version":"3.2","default":null,"dependencies":null,"maintainer":"hello@civo.com","description":"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.","post_install":"## Redis - in-memory DB and cache\n\n### External access\n\nBy default external access to the Redis port isn't available. This is easily changed by applying the following YAML to your cluster with `kubectl apply -f redis-service.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 6379\n      targetPort: 6379\n      protocol: TCP\n  selector:\n    app: redis\n```\n\nThis will open up http://YOUR_CLUSTER_ID.k8s.civo.com:6379 to the whole world. You should lock this down in the [firewall](https://www.civo.com/account/firewalls) automatically created in Civo for your Kubernetes cluster. Locking down the firewall will only affect access from OUTSIDE of your Kubernetes cluster, access from your applications within Kubernetes will not be affected.\n\n### Usage instructions\n\nYou can use this application from within your cluster by just using the hostname `redis` and the password above this message. For example, to connect to Redis inside your cluster to test it or look at its data, you could do something like this:\n\n```\n$ kubectl run tmp-shell --generator=run-pod/v1 --rm -i --tty \\\n  --image alpine -- /bin/sh\n/ # apk update\n/ # apk add redis\n/ # redis-cli -h redis -a YOUR_PASSWORD_HERE\nredis:6379\u003e \n```\n\nWhen you quit the shell the pod for this temporary Alpine container will be deleted.\n","url":"https://redis.io","category":"database","image_url":"https://api.civo.com/k3s-marketplace/redis.png","plans":null},{"name":"sealed-secrets","title":"Sealed Secrets","version":"v0.12.4","default":null,"dependencies":null,"maintainer":"@soukron","description":"A Kubernetes controller and tool for one-way encrypted Secrets","post_install":"## sealed-secrets -  a Kubernetes controller and tool for one-way encrypted Secrets \n\n### Client installation\n\nInstall client-side tool from [0.12.4 release page](https://github.com/bitnami-labs/sealed-secrets/releases/tag/v0.12.4)\n\n### Usage\n\n```sh\n# Create a json/yaml-encoded Secret somehow:\n# (note use of `--dry-run` - this is just a local file!)\n$ echo -n bar | kubectl create secret generic mysecret --dry-run --from-file=foo=/dev/stdin -o json \u003emysecret.json\n\n# This is the important bit:\n# (note default format is json!)\n$ kubeseal \u003cmysecret.json \u003emysealedsecret.json\n\n# mysealedsecret.json is safe to upload to github, post to twitter,\n# etc.  Eventually:\n$ kubectl create -f mysealedsecret.json\n\n# Profit!\n$ kubectl get secret mysecret\n```\n\n* Official [sealed-secret docs](https://github.com/bitnami-labs/sealed-secrets#overview)\n","url":"https://github.com/bitnami-labs/sealed-secrets","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/sealed-secrets.png","plans":null},{"name":"Selenium","title":null,"version":"3.141.59-r1","default":null,"dependencies":null,"maintainer":"scndeldev@gmail.com","description":"Selenium is a framework for testing web applications. PLEASE PROVIDE AT LEAST 2 GB MEMORY FOR STABILITY.","post_install":"## Selenium\n\nThis is a ready Selenium hub with Chrome node\n\n### External access\n\nBy default external access to the Selenium hub to connect external nodes or to reach web console is disabled. This is easily changed by applying the following YAML to apply ingress via traefik to your cluster with `kubectl apply -f selenium-ingress.yaml` (or whatever you call the file containing the contents below):\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: selenium-hub-ingress\nspec:\n  rules:\n  - host: selenium.\u003cyour-cluster-id\u003e.k8s.civo.com\n    http:\n      paths:\n      - backend:\n          serviceName: selenium-hub\n          servicePort: 4444\n```\n\n### Usage instruction\n\nGo to `http://selenium.\u003cyour-cluster-id\u003e.k8s.civo.com` to access console\nJust add `http://selenium.\u003cyour-cluster-id\u003e.k8s.civo.com` as your webdriver remote url for your test scripts. \n\n### Scaling (experimental)\n\nYou might scale the amount of Selenium Chrome nodes with :\n`kubectl scale --replicas=\u003camount\u003e deployment/selenium-node-chrome`\nbut be careful not to overload your cluster. Adapt the size or scale your Civo cluster accordingly (2GB per Selenium node).  \n","url":"https://www.seleniumhq.org","category":"ci_cd","image_url":"https://api.civo.com/k3s-marketplace/selenium.png","plans":null},{"name":"system-upgrade-controller","title":null,"version":"v0.6.2","default":null,"dependencies":null,"maintainer":"@curx","description":"A general-purpose, Kubernetes-native upgrade controller (for nodes).","post_install":"## system-upgrade-contoller - a general-purpose, Kubernetes-native upgrade controller (for nodes)\n\n### Important warning\n\nIf you use this to upgrade your cluster, the version we believe you have installed and the version you actually have installed will forever differ. We understand some people want to stay closer to the latest releases than we can sometimes offer, but here be dragons...\n\n### Get started\n\nFull documentation is available from Rancher at [system-upgrade-controller](https://github.com/rancher/system-upgrade-controller)\n\nThere are some [example-plans](https://github.com/rancher/system-upgrade-controller#example-plans) for you to consider using.\n\nA plan is need to start upgrade process on cluster. This is easily by applying the following yaml manifests to your cluster with\n`kubectl apply -f civo-plan.yaml` (or whatever you call the file containing the contents below):\n\n```\n# Server plan\napiVersion: upgrade.cattle.io/v1\nkind: Plan\nmetadata:\n  name: server-plan\n  namespace: system-upgrade\nspec:\n  concurrency: 1\n  cordon: true\n  nodeSelector:\n    matchExpressions:\n    - key: node-role.kubernetes.io/master\n      operator: In\n      values:\n      - \"true\"\n  serviceAccountName: system-upgrade\n  upgrade:\n    image: rancher/k3s-upgrade\n  channel: https://update.k3s.io/v1-release/channels/v1.16\n---\n# Agent plan\napiVersion: upgrade.cattle.io/v1\nkind: Plan\nmetadata:\n  name: agent-plan\n  namespace: system-upgrade\nspec:\n  concurrency: 1\n  cordon: true\n  nodeSelector:\n    matchExpressions:\n    - key: node-role.kubernetes.io/master\n      operator: DoesNotExist\n  prepare:\n    args:\n    - prepare\n    - server-plan\n    image: rancher/k3s-upgrade:v1.17.4-k3s1\n  serviceAccountName: system-upgrade\n  upgrade:\n    image: rancher/k3s-upgrade\n  channel: https://update.k3s.io/v1-release/channels/v1.16\n```\n\nThis will create the plan for the `system-update-controller` and on the Civo kubernetes nodes the k3s version will be updated to the last (stable) version.\n\nCheck it via `kubectl get nodes --output wide`\n","url":"https://github.com/rancher/system-upgrade-controller","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/system-upgrade-controller.png","plans":null},{"name":"Tekton","title":null,"version":"v0.17.0","default":null,"dependencies":null,"maintainer":"me@r15cookie.com","description":"Tekton is a Kubernetes Native Framework for building CI/CD Pipelines.  The core pipeline, dashboard, and trigger components are included.","post_install":"## Tekton\n\nThis marketplace application installs three components of the Tekton Suite.  Those are the core Pipeline, along with Triggers and the Dashboard.  \n\n### Usage Instructions\n\n- [Getting Started](https://tekton.dev/docs/getting-started/)\n- [Full Documentation](https://tekton.dev/docs/)\n- [Triggers](https://tekton.dev/docs/triggers/)\n- [Dashboard](https://tekton.dev/docs/dashboard/)\n\n### Dashboard Access\n\nBy default external access to the Tekton Dashboard isn't available.  As there is no built-in authentication method, it should not be exposed\nvia an Ingress without additional authentication methods in place.  To easily and securely access the dashboard, use port forwarding, which will make the dashboard available at \u003chttp://localhost:9097\u003e\n\n```sh\nkubectl --namespace tekton-pipelines port-forward svc/tekton-dashboard 9097:9097\n```\n\n### Exposing Trigger EventListeners\n\nIncoming triggers can be exposed through an Ingress.  [The core instructions](https://tekton.dev/docs/triggers/exposing-eventlisteners/) can be used with the following modifications:\n\n1. Skip step one under \"Using Nginx Ingress\", as the Traefik ingress should work\n2. Obtain the event-lister with a `kubectl get el \u003cEVENTLISTENR_NAME\u003e -o=jsonpath='{.status.configuration.generatedName}'` command\n3. With the service name, create an ingress as below:\n   ```yaml\n    apiVersion: extensions/v1beta1\n    kind: Ingress\n    metadata:\n      name: ingress-resource\n      namespace: getting-started\n    spec:\n      rules:\n        - http:\n          host: eventlistenername.your-cluster-id.k8s.civo.com\n            paths:\n              - path: /\n                backend:\n                  serviceName: getting-started-listener-b8rqz # REPLACE WITH YOUR SERVICE NAME FROM STEP 2\n                  servicePort: 8080\n   ```\n\nThis will open up http://eventlistenername.YOUR_CLUSTER_ID.k8s.civo.com to trigger the service.  Ensure your event-listener has the necessary interceptor configuration in place to prevent unauthorized triggering of the pipeline.","url":"https://cloud.google.com/tekton","category":"ci_cd","image_url":"https://api.civo.com/k3s-marketplace/tekton.png","plans":null},{"name":"Traefik","title":null,"version":"(default)","default":true,"dependencies":null,"maintainer":"@Rancher_Labs","description":"A reverse proxy/load-balancer that's easy, dynamic, automatic, fast, full-featured, open source, production proven and provides metrics.","post_install":"## Traefik - Default ingress controller\n\n### External access to your services\n\nTraefik is installed in K3s as the default ingress controller. To use it for your applications all you have to do is apply a YAML file like the one below to handle ingress:\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: yourapp-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: www.example.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: yourapp-service\n          servicePort: http\n```\n\nThis will open up http://www.example.com (assuming you pointed that non-real domain record to your cluster's IPs) to the whole world.\n","url":"https://traefik.io","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/traefik.png","plans":null},{"name":"Traefik-v2","title":"Traefik v2","version":"2.3","default":false,"dependencies":null,"maintainer":"johannes@jitesoft.com","description":"An open source Edge Router working as an ingress controller and load balancer inside your kubernetes cluster.","post_install":"## Traefik (v2) - Ingress Controller\n\nTraefik is a open source Edge Router which is usable as a ingress controller for kubernetes.  \nIt supports both the kubernetes Ingress object (`extensions/v1beta1`) as well as the traefik provided CDRs (custom resource definition).\n\nTrafik is very customizable and can do very much for you, but all of its features can not be covered in this message,\nif you wish to find more information, check out the [official documentation](https://doc.traefik.io/traefik/)!\n\n### External access to your services\n\nTo expose a standard http service to the external net, you can either use the kubernetes internal Ingress object as follows:\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: yourapp-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: www.example.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: yourapp-service\n          servicePort: http\n```\n\nTraefik also includes a CDR called IngressRoute, which would look like this:\n\n```\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: yourapp-ingress\n  namespace: default\nspec:\n  entryPoints:\n    - web\n    - websecure\n  routes:\n    - kind: Rule\n      match: (Path(`/`)\n      services:\n        - kind: Service\n          name: yourapp-service\n          namespace: default\n          port: http\n```\n\nThis will open up http://www.example.com (assuming you pointed that non-real domain record to your cluster's IPs) to the whole world.\n\n\nPort 80 and 443 are both exposed through a `LoadBalancer` service, with the help of [cert-manager](https://cert-manager.io/) you can\nissue your own TLS/SSL certificates for your domains, by default, Traefik generates a self-signed certificate for the\nwebsecure endpoint (443). \n","url":"https://traefik.io","category":"architecture","image_url":"https://api.civo.com/k3s-marketplace/traefik2.png","plans":null},{"name":"Wordpress","title":null,"version":"5.6.2","default":null,"dependencies":["longhorn","mariadb:5GB"],"maintainer":"javicv@gmail.com, amit2cha@gmail.com","description":"WordPress is open source software you can use to create a beautiful website, blog, or app.","post_install":"# WordPress\n\n## Database Creation\n\nYou'll need to create a user and a database in MariaDB before you can configure your Wordpress.\n\n```\n$ kubectl exec -it svc/mariadb -- /bin/sh\n\n# mysql -u root -p\nEnter password: YOUR_ROOT_PASSWORD_HERE\n\nMariaDB [(none)]\u003e CREATE DATABASE wordpress_db;\nMariaDB [(none)]\u003e CREATE USER wordpress_user identified by 'strong-password';\nMariaDB [(none)]\u003e GRANT ALL ON wordpress_db.* TO wordpress_user;\n```\n\n## SSL behind a proxy server\n\nTraefik works as a proxy server, so you need to alert WordPress of that fact. Without this configuration you'll see a **too many redirects** error when accessing the page.\n\nTo simplify this configuration when the WordPress is installed an script is created to add the required lines to the *wp-config-sample.php*\n\nUse the following command to execute it when your WordPress pod reach running state.\n\n```\n kubectl exec -it svc/wordpress -- bash -c /var/www/html/civo-init.sh\n```\n\nAfter the script execution the following lines will be added to the *wp-config-sample.php* file, and they will be present in wp-config.php after wizard setup.\n\n```\nif (isset($_SERVER['HTTP_X_FORWARDED_PROTO']) \u0026\u0026 $_SERVER['HTTP_X_FORWARDED_PROTO'] === 'https') {\n        $_SERVER['HTTPS'] = 'on';\n}\n```\n\n## WordPress Wizard Setup\n\nThe first time you access to your WordPress a wizard setup will be loaded. In the first step you will select the language, and then you will be asked for your database connection information.\n\nBased on the database creation example above, the fields would be filled like this:\n\n* **Database Name:** *wordpress_db*\n* **Username:** *wordpress_user*\n* **Password:** *strong-password*\n* **Database Host:** *mariadb*\n* **Table Prefix:** *wp_*\n\n## External Access\n\nAn Ingress is created during the installation process. To access your wordpress use http://wordpress.YOUR_CLUSTER_ID.k8s.civo.com\n\nIf you want to change the hostname or modify the ingress, edit it with\n```\nkubectl edit ingress wordpress\n```\n","url":"https://wordpress.org","category":"management","image_url":"https://api.civo.com/k3s-marketplace/wordpress.png","plans":[{"label":"5GB","configuration":{"VOLUME_SIZE":{"value":"5Gi"}}},{"label":"10GB","configuration":{"VOLUME_SIZE":{"value":"10Gi"}}},{"label":"20GB","configuration":{"VOLUME_SIZE":{"value":"20Gi"}}}]}]